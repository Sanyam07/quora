# Sets of stop words for tokenizers in tokenizers.py.

GNEWS_STOP_WORDS = set("""? to a of and , . " - ) ( / ' : ! [ ] ... ; { } .. < > '' """.split())